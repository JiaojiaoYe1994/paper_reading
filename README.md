# paper_reading

## 2023
[2023-09-22][paper27]
* Learning to summarize from human feedback
* `NIPS 2020`
* [paper](https://arxiv.org/abs/2009.01325)
* [code](https://github.com/openai/summarize-from-feedback)
* OpenAI
* `reinforcement learning`, `fine tuning`, `language model`

[23-09-20] [paper26]
* Fine-Tuning Language Models from Human Preferences
* `2020-01`
* [paper](https://arxiv.org/abs/1909.08593)
* OpenAI
* `reinforcement learning`, `large language model`, `fine-tuning`

[23-09-18] [paper25]
* RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback
* `2023-09`
* [paper](https://arxiv.org/abs/2309.00267)
* Google Research
* `reinforcement learning`, `large language model`, `fine-tuning`

[23-09-13] [paper24]
* Champion-level drone racing using deep reinforcement learning
* `2023 Nature`
* [paper](https://www.nature.com/articles/s41586-023-06419-4)
* [video](https://www.youtube.com/watch?v=fBiataDpGIo)
* University of Zurich, Intel Labs, Munich, Germany. Intel Labs, Jackson, WY, USA
* `Reinforcement Learning`, `Robotics`, `mobile robotics`

[23-09-08] [paper23]
* On the Opportunities and Risks of Foundation Models


[23-09-06] [paper22]
* PTQD: Accurate Post-Training Quantization for Diffusion Models
* `2023-05`
* [paper](https://arxiv.org/pdf/2305.10657.pdf)
* Zhejiang University, Monash University
* `diffusion model`, `quantization`, `image generation`
  
[23-09-05] [paper21]
* On Architectural Compression of Text-to-Image Diffusion Models
* `2023-05`
* [paper](https://arxiv.org/pdf/2305.15798.pdf)
* Nota Inc., South Korea
* `diffusion model`, `compression`, `text-to-image generation`
  
[23-08-28] [paper20]
* Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding
* `NIPs 2022`
* [paper](https://openreview.net/pdf?id=08Yk-n5l2Al)
* [blog](https://imagen.research.google/)
* Google Research, Brain Team
* `diffusion model`, `computer vision`, `text-to-image generation`
  
[23-08-24] [paper19]
* QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization
* `ICLR 2022`
* [paper](https://arxiv.org/abs/2203.05740)
* [code](https://github.com/wimh966/QDrop)
* Beihang University, 2SenseTime Researc
* `quantizarion`, `computer vision`
  
[23-08-21] [paper18]
* Post-training Quantization on Diffusion Models
* `CVPR 2023` Illinois Institute of Technology, Houmo AI, Tencent AI Lab, Cisco Research
* [paper](https://arxiv.org/abs/2211.15736)
* [blog](https://zhuanlan.zhihu.com/p/632960679)
* [code](https://github.com/42Shawn/PTQ4DM)
* `diffusion model`, `generative model`, `quantization`
  
[23-08-14] [paper17]
* Palette: Image-to-Image Diffusion Models
* `2022-05` Google Research Brain Team
* [paper](https://arxiv.org/pdf/2111.05826.pdf)
* [blog](https://iterative-refinement.github.io/palette/)
* [code](https://github.com/Janspiry/Palette-Image-to-Image-Diffusion-Models)
* `diffusion model`, `generative model`, `img2img translation`

[23-08-11] [paper16]
* Prompt-to-Prompt Image Editing with Cross Attention 
* `ICLR 2023` Google Research Brain Team
* [paper](https://arxiv.org/pdf/2208.01626.pdf)
* [blog](https://prompt-to-prompt.github.io/)
* [code](https://github.com/google/prompt-to-prompt)
* `diffusion model`, `generative model`, `image editing`
  
[23-08-11] [paper15]
* Video Diffusion Models
* `NIPs 2022` Google Research Brain Team
* [paper](https://arxiv.org/abs/2207.12598)
* [blog](https://video-diffusion.github.io/)
* `diffusion model`, `generative model`, `video generation`

[23-08-10] [paper14]
* Classifier-Free Diffusion Guidance
* `2022` Google Research Brain Team
* [paper](https://arxiv.org/abs/2207.12598)
* `diffusion model`, `generative model`

[23-08-10] [paper13]
* GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models
* `2022-03` OpenAI
* [paper](https://arxiv.org/pdf/2112.10741.pdf)
* [code](https://github.com/openai/glide-text2im)
* `diffusion model`, `generative model`, `multimodal`

[23-08-09] [paper12]
* DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation
* `CVPR 2023`
* [paper](https://arxiv.org/pdf/2208.12242.pdf)
* [code](https://dreambooth.github.io/)
* `diffusion model`, `generative model`, `fine tuning`  
  
[23-08-09] [paper11]
* A Survey on Generative Diffusion Model
* `2022-12`
* [paper](https://arxiv.org/pdf/2209.02646.pdf)
* `survey` , `diffusion model`, `generative model`
  
[23-08-08] [paper10]
* Diffusion Models: A Comprehensive Survey of Methods and Applications 
* `2023-03`
* [paper](https://arxiv.org/pdf/2209.00796.pdf)
* `survey` , `diffusion model`, `generative model`

[23-08-07] [paper9]
* LDM - High-Resolution Image Synthesis with Latent Diffusion Models
* `CVPR 2022`
* [paper](https://arxiv.org/pdf/2209.00796.phttps://arxiv.org/pdf/2112.10752.pdf)
* [code](https://github.com/CompVis/latent-diffusion)
* [my tutorial](https://zhuanlan.zhihu.com/p/622119008)
* `diffusion model`, `generative model`, `mutlimodal`

[23-08-04] [paper8]
* Q-Diffusion: Quantizing Diffusion Models
* `ICCV 2023`
* [paper](https://arxiv.org/pdf/2302.04304.pdf)
* [code](https://github.com/Xiuyu-Li/q-diffusion)
* [blog](https://xiuyuli.com/qdiffusion/)
* `diffusion model`, `generative model`, `quantization`

[23-08-04] [paper7]
* ADM - Diffusion Models Beat GANs on Image Synthesis
* `2021-06`
* [paper](https://arxiv.org/pdf/2105.05233.pdf)
* `diffusion model`, `generative model`,

[23-08-03] [paper6]
* ControlNet - Adding Conditional Control to Text-to-Image Diffusion Models
* `2023-02` 
* [paper](https://arxiv.org/pdf/2302.05543.pdf)
* [code](https://github.com/lllyasviel/ControlNet)
* Stanford
* `diffusion model`, `generative model`

[23-08-02] [paper5]
* A Survey on Generative Diffusion Models
* `2022-12` 
* [paper](https://arxiv.org/pdf/2209.02646.pdf)
* CUHK, ZJU, MIT
* `diffusion model`, `generative model`,  `survey`  

[23-08-02] [paper4]
* Diffusion Models: A Comprehensive Survey of Methods and Applications
* `2023-03` 
* [paper](https://arxiv.org/pdf/2209.00796.pdf)
* PKU, OpenAI, UCLA, CMU, Mila
* `diffusion model`, `generative model`,  `survey`

[23-08-01] [paper3]
* DDIM - Denoising Implicit Models
* `ICLR 2021` 
* [paper](https://arxiv.org/pdf/2010.02502.pdf)
* [code](https://github.com/ermongroup/ddim)
* Stanford
* `diffusion model`, `generative model`

[23-07-31] [paper2]
* Denoising Diffusion Probabilistic Models
* `NIPs 2020` 
* [paper](https://arxiv.org/abs/2006.11239)
* [blog](https://hojonathanho.github.io/diffusion/)
* [code](https://github.com/hojonathanho/diffusion)
* UC Berkeley
* `diffusion model`, `generative model`

[23-07-28] [paper1]
* On the Opportunities and Risks of Foundation Models
* `2022-07` 
* [paper]([https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2108.07258))
* [video](https://www.youtube.com/watch?v=ZshcPdavsdU)
* [blog](https://crfm.stanford.edu/report.html)
* Stanford University
* `foundation model`

