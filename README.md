# paper_reading

## 2023
[23-08-11] [paper17]
* Palette: Image-to-Image Diffusion Models
* `2022-05` Google Research Brain Team
* [paper](https://arxiv.org/pdf/2111.05826.pdf)
* [blog](https://iterative-refinement.github.io/palette/)
* [code](https://github.com/Janspiry/Palette-Image-to-Image-Diffusion-Models)
* `diffusion model`, `generative model`, `img2img translation`

[23-08-11] [paper16]
* Prompt-to-Prompt Image Editing with Cross Attention 
* `ICLR 2023` Google Research Brain Team
* [paper](https://arxiv.org/pdf/2208.01626.pdf)
* [blog](https://prompt-to-prompt.github.io/)
* [code](https://github.com/google/prompt-to-prompt)
* `diffusion model`, `generative model`, `image editing`
  
[23-08-11] [paper15]
* Video Diffusion Models
* `NIPs 2022` Google Research Brain Team
* [paper](https://arxiv.org/abs/2207.12598)
* [blog](https://video-diffusion.github.io/)
* `diffusion model`, `generative model`, `video generation`

[23-08-10] [paper14]
* Classifier-Free Diffusion Guidance
* `2022` Google Research Brain Team
* [paper](https://arxiv.org/abs/2207.12598)
* `diffusion model`, `generative model`

[23-08-10] [paper13]
* GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models
* `2022-03` OpenAI
* [paper](https://arxiv.org/pdf/2112.10741.pdf)
* [code](https://github.com/openai/glide-text2im)
* `diffusion model`, `generative model`, `multimodal`

[23-08-09] [paper12]
* DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation
* `CVPR 2023`
* [paper](https://arxiv.org/pdf/2208.12242.pdf)
* [code](https://dreambooth.github.io/)
* `diffusion model`, `generative model`, `fine tuning`  
  
[23-08-09] [paper11]
* A Survey on Generative Diffusion Model
* `2022-12`
* [paper](https://arxiv.org/pdf/2209.02646.pdf)
* `survey` , `diffusion model`, `generative model`
  
[23-08-08] [paper10]
* Diffusion Models: A Comprehensive Survey of Methods and Applications 
* `2023-03`
* [paper](https://arxiv.org/pdf/2209.00796.pdf)
* `survey` , `diffusion model`, `generative model`

[23-08-07] [paper9]
* LDM - High-Resolution Image Synthesis with Latent Diffusion Models
* `CVPR 2022`
* [paper](https://arxiv.org/pdf/2209.00796.phttps://arxiv.org/pdf/2112.10752.pdf)
* [code](https://github.com/CompVis/latent-diffusion)
* [my tutorial](https://zhuanlan.zhihu.com/p/622119008)
* `diffusion model`, `generative model`, `mutlimodal`

[23-08-05] [paper8]
* Q-Diffusion: Quantizing Diffusion Models
* `ICCV 2023`
* [paper](https://arxiv.org/pdf/2302.04304.pdf)
* [code](https://github.com/Xiuyu-Li/q-diffusion)
* [blog](https://xiuyuli.com/qdiffusion/)
* `diffusion model`, `generative model`, `quantization`

[23-08-04] [paper7]
* ADM - Diffusion Models Beat GANs on Image Synthesis
* `2021-06`
* [paper](https://arxiv.org/pdf/2105.05233.pdf)
* `diffusion model`, `generative model`,

[23-08-04] [paper6]
* ControlNet - Adding Conditional Control to Text-to-Image Diffusion Models
* `2023-02` 
* [paper](https://arxiv.org/pdf/2302.05543.pdf)
* [code](https://github.com/lllyasviel/ControlNet)
* Stanford
* `diffusion model`, `generative model`
