# paper_reading

## 2023
[2023-12-06][paper39]
* Enhancing Perceptual Quality in Video Super-Resolution through Temporally-Consistent Detail Synthesis using Diffusion Models
* `2023`
* [paper](https://arxiv.org/abs/2311.15908)
* C Rota, M Buzzelli, J van de Weijer
* `multi-agent reinforcement learning`, `survey`
  
[2023-12-04][paper38]
* Multi-Agent Reinforcement Learning: Foundations and Modern Approaches
* `2013`
* [paper](https://www.marl-book.com/download/marl-book.pdf)
* Stefano V. Albrecht, Filippos Christianos, Lukas Schäfer, The University of Edinburgh
* `multi-agent reinforcement learning`, `survey`
  
[2023-11-27][paper37]
* A Survey of Learning in Multiagent Environments: Dealing with Non-Stationarity
* `2017`
* [paper](https://arxiv.org/pdf/1707.09183.pdf)
* Centrum Wiskunde & Informatica, Instituto Nacional de Astrof´ısica, Optica y Electr´onica, Puebla, M´exico
* `multi-agent reinforcement learning`, `survey`
    
[2023-11-23][paper36]
* Inductive Representation Learning on Large Graphs
* `Nips 2017`
* [paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf)
* William L. Hamilton, Rex Ying, Jure Leskovec, Stanford University
* `Representation Learning`, `graph neural network`

[2023-11-20][paper35]
* Human motion diffusion model.
  
[2023-11-15][paper34]
* Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms. 
* `Springer Handbook of Reinforcement Learning and Control 2021`
* [paper](https://link.springer.com/chapter/10.1007/978-3-030-60990-0_12)
* Kaiqing Zhang, Zhuoran Yang, Tamer Başar
* `reinforcement learning`, `survey`
  
[2023-11-08][paper33]
* Is Conditional Generative Modeling All You Need for Decision-Making?
* `ICLR 2023`
* * [paper](https://arxiv.org/pdf/2211.15657v3.pdf)
* `diffusion model`, `reinforcement learning`
  
[2023-11-07][paper32]
* Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling
* `ICLR 2023`
* [paper](https://arxiv.org/pdf/2301.12050.pdf)
* [openreview](https://openreview.net/forum?id=Z_qiOvqvnBl&referrer=%5Bthe%20profile%20of%20Yejin%20Choi%5D(%2Fprofile%3Fid%3D~Yejin_Choi1))
* University of California Irvine, Allen Institute for Artificial Intelligence, Paul G. Allen School of Computer Science
* `reinforcement learning`, `LLM`, `world model`

[2023-11-03][paper31]
* Image retrieval outperforms diffusion models on data augmentation
* `2023`
* [paper](https://openreview.net/forum?id=xflYdGZMpv)
*  `diffusion model`, `computer vision`, `information retrieval`

[2023-11-03][paper31]
* StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing
* [paper](https://arxiv.org/pdf/2303.15649.pdf)
* [code](https://github.com/sen-mao/StyleDiffusion)
* UAB
* `diffusion model`, `computer vision`, `image editing`

[2023-11-02][paper30]
* Effective Data Augmentation With Diffusion Models
* `ICCV 2023` 
* [paper](https://arxiv.org/abs/2302.07944)
* [code](https://github.com/brandontrabucco/da-fusion)
* CMU
* `diffusion model`, `computer vision`, `data augmentation`

[2023-10-16][paper29]
* DiffusionDet: Diffusion Model for Object Detection
* `ICCV 2023` 
* [paper](https://arxiv.org/abs/2211.09788)
* [code](https://github.com/ShoufaChen/DiffusionDet)
* The University of Hong Kong， Tencent AI Lab， Fudan University， Shanghai AI Laboratory
* `diffusion model`, `object detection`

[2023-09-25][paper28]
* Deep Reinforcement Learning　from Human Preferences
* `NIPS 2017`
* [paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf)
* [code](https://github.com/mrahtz/learning-from-human-preferences)
* OpenAI, Google
* `reinforcement learning`, `fine tuning`, `language model`

[2023-09-22][paper27]
* Learning to summarize from human feedback
* `NIPS 2020`
* [paper](https://arxiv.org/abs/2009.01325)
* [code](https://github.com/openai/summarize-from-feedback)
* OpenAI
* `reinforcement learning`, `fine tuning`, `language model`

[23-09-20] [paper26]
* Fine-Tuning Language Models from Human Preferences
* `2020-01`
* [paper](https://arxiv.org/abs/1909.08593)
* OpenAI
* `reinforcement learning`, `large language model`, `fine-tuning`

[23-09-18] [paper25]
* RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback
* `2023-09`
* [paper](https://arxiv.org/abs/2309.00267)
* Google Research
* `reinforcement learning`, `large language model`, `fine-tuning`

[23-09-13] [paper24]
* Champion-level drone racing using deep reinforcement learning
* `2023 Nature`
* [paper](https://www.nature.com/articles/s41586-023-06419-4)
* [video](https://www.youtube.com/watch?v=fBiataDpGIo)
* University of Zurich, Intel Labs, Munich, Germany. Intel Labs, Jackson, WY, USA
* `Reinforcement Learning`, `Robotics`, `mobile robotics`

[23-09-08] [paper23]
* On the Opportunities and Risks of Foundation Models


[23-09-06] [paper22]
* PTQD: Accurate Post-Training Quantization for Diffusion Models
* `2023-05`
* [paper](https://arxiv.org/pdf/2305.10657.pdf)
* Zhejiang University, Monash University
* `diffusion model`, `quantization`, `image generation`
  
[23-09-05] [paper21]
* On Architectural Compression of Text-to-Image Diffusion Models
* `2023-05`
* [paper](https://arxiv.org/pdf/2305.15798.pdf)
* Nota Inc., South Korea
* `diffusion model`, `compression`, `text-to-image generation`
  
[23-08-28] [paper20]
* Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding
* `NIPs 2022`
* [paper](https://openreview.net/pdf?id=08Yk-n5l2Al)
* [blog](https://imagen.research.google/)
* Google Research, Brain Team
* `diffusion model`, `computer vision`, `text-to-image generation`
  
[23-08-24] [paper19]
* QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization
* `ICLR 2022`
* [paper](https://arxiv.org/abs/2203.05740)
* [code](https://github.com/wimh966/QDrop)
* Beihang University, 2SenseTime Researc
* `quantizarion`, `computer vision`
  
[23-08-21] [paper18]
* Post-training Quantization on Diffusion Models
* `CVPR 2023` Illinois Institute of Technology, Houmo AI, Tencent AI Lab, Cisco Research
* [paper](https://arxiv.org/abs/2211.15736)
* [blog](https://zhuanlan.zhihu.com/p/632960679)
* [code](https://github.com/42Shawn/PTQ4DM)
* `diffusion model`, `generative model`, `quantization`
  
[23-08-14] [paper17]
* Palette: Image-to-Image Diffusion Models
* `2022-05` Google Research Brain Team
* [paper](https://arxiv.org/pdf/2111.05826.pdf)
* [blog](https://iterative-refinement.github.io/palette/)
* [code](https://github.com/Janspiry/Palette-Image-to-Image-Diffusion-Models)
* `diffusion model`, `generative model`, `img2img translation`

[23-08-11] [paper16]
* Prompt-to-Prompt Image Editing with Cross Attention 
* `ICLR 2023` Google Research Brain Team
* [paper](https://arxiv.org/pdf/2208.01626.pdf)
* [blog](https://prompt-to-prompt.github.io/)
* [code](https://github.com/google/prompt-to-prompt)
* `diffusion model`, `generative model`, `image editing`
  
[23-08-11] [paper15]
* Video Diffusion Models
* `NIPs 2022` Google Research Brain Team
* [paper](https://arxiv.org/abs/2207.12598)
* [blog](https://video-diffusion.github.io/)
* `diffusion model`, `generative model`, `video generation`

[23-08-10] [paper14]
* Classifier-Free Diffusion Guidance
* `2022` Google Research Brain Team
* [paper](https://arxiv.org/abs/2207.12598)
* `diffusion model`, `generative model`

[23-08-10] [paper13]
* GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models
* `2022-03` OpenAI
* [paper](https://arxiv.org/pdf/2112.10741.pdf)
* [code](https://github.com/openai/glide-text2im)
* `diffusion model`, `generative model`, `multimodal`

[23-08-09] [paper12]
* DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation
* `CVPR 2023`
* [paper](https://arxiv.org/pdf/2208.12242.pdf)
* [code](https://dreambooth.github.io/)
* `diffusion model`, `generative model`, `fine tuning`  
  
[23-08-09] [paper11]
* A Survey on Generative Diffusion Model
* `2022-12`
* [paper](https://arxiv.org/pdf/2209.02646.pdf)
* `survey` , `diffusion model`, `generative model`
  
[23-08-08] [paper10]
* Diffusion Models: A Comprehensive Survey of Methods and Applications 
* `2023-03`
* [paper](https://arxiv.org/pdf/2209.00796.pdf)
* `survey` , `diffusion model`, `generative model`

[23-08-07] [paper9]
* LDM - High-Resolution Image Synthesis with Latent Diffusion Models
* `CVPR 2022`
* [paper](https://arxiv.org/pdf/2209.00796.phttps://arxiv.org/pdf/2112.10752.pdf)
* [code](https://github.com/CompVis/latent-diffusion)
* [my tutorial](https://zhuanlan.zhihu.com/p/622119008)
* `diffusion model`, `generative model`, `mutlimodal`

[23-08-04] [paper8]
* Q-Diffusion: Quantizing Diffusion Models
* `ICCV 2023`
* [paper](https://arxiv.org/pdf/2302.04304.pdf)
* [code](https://github.com/Xiuyu-Li/q-diffusion)
* [blog](https://xiuyuli.com/qdiffusion/)
* `diffusion model`, `generative model`, `quantization`

[23-08-04] [paper7]
* ADM - Diffusion Models Beat GANs on Image Synthesis
* `2021-06`
* [paper](https://arxiv.org/pdf/2105.05233.pdf)
* `diffusion model`, `generative model`,

[23-08-03] [paper6]
* ControlNet - Adding Conditional Control to Text-to-Image Diffusion Models
* `2023-02` 
* [paper](https://arxiv.org/pdf/2302.05543.pdf)
* [code](https://github.com/lllyasviel/ControlNet)
* Stanford
* `diffusion model`, `generative model`

[23-08-02] [paper5]
* A Survey on Generative Diffusion Models
* `2022-12` 
* [paper](https://arxiv.org/pdf/2209.02646.pdf)
* CUHK, ZJU, MIT
* `diffusion model`, `generative model`,  `survey`  

[23-08-02] [paper4]
* Diffusion Models: A Comprehensive Survey of Methods and Applications
* `2023-03` 
* [paper](https://arxiv.org/pdf/2209.00796.pdf)
* PKU, OpenAI, UCLA, CMU, Mila
* `diffusion model`, `generative model`,  `survey`

[23-08-01] [paper3]
* DDIM - Denoising Implicit Models
* `ICLR 2021` 
* [paper](https://arxiv.org/pdf/2010.02502.pdf)
* [code](https://github.com/ermongroup/ddim)
* Stanford
* `diffusion model`, `generative model`

[23-07-31] [paper2]
* Denoising Diffusion Probabilistic Models
* `NIPs 2020` 
* [paper](https://arxiv.org/abs/2006.11239)
* [blog](https://hojonathanho.github.io/diffusion/)
* [code](https://github.com/hojonathanho/diffusion)
* UC Berkeley
* `diffusion model`, `generative model`

[23-07-28] [paper1]
* On the Opportunities and Risks of Foundation Models
* `2022-07` 
* [paper]([https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2108.07258))
* [video](https://www.youtube.com/watch?v=ZshcPdavsdU)
* [blog](https://crfm.stanford.edu/report.html)
* Stanford University
* `foundation model`

